{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the patient Profile:\n",
      "name: Avijit bhuin\n",
      "age: 22\n",
      "gender: Male\n",
      "blood_group: A+\n",
      "symptoms: fever\n",
      "\n",
      "Chat History:\n",
      "Assistant: I understand your concern about 'hii'. This is a placeholder response. In a real implementation, this would be connected to a medical AI model that can provide appropriate medical guidance while noting that it's not a replacement for professional medical advice.\n",
      "User: hii\n",
      "\n",
      "Assistant: okk\n",
      "User: okk\n",
      "\n",
      "\n",
      "Total question count: 2\n"
     ]
    }
   ],
   "source": [
    "def get_prompt(patient_data, conversation):\n",
    "        base_prompt = \"\"\"This is the patient Profile:\\n\"\"\"\n",
    "        for i in patient_data:\n",
    "            if patient_data[i] != '':\n",
    "                base_prompt += f'''{i}: {patient_data[i]}\\n'''\n",
    "\n",
    "        \n",
    "\n",
    "        formatted_conversation = \"Chat History:\\n\"\n",
    "        question_count = 0\n",
    "\n",
    "        for i, message in enumerate(conversation):\n",
    "            if message['role'] == 'assistant':\n",
    "                question_count += 1\n",
    "                # formatted_conversation += f\"This is the {question_count}th question\\n\"\n",
    "                formatted_conversation += f\"Assistant: {message['content']}\\n\"\n",
    "                if i + 1 < len(conversation) and conversation[i + 1]['role'] == 'user':\n",
    "                    formatted_conversation += f\"User: {conversation[i + 1]['content']}\\n\\n\"\n",
    "                else:\n",
    "                    formatted_conversation += \"\\n\"\n",
    "            elif message['role'] == 'assistant' and (i == 0 or conversation[i - 1]['role'] != 'user'):\n",
    "                formatted_conversation += f\"Assistant: {message['content']}\\n\\n\"\n",
    "        \n",
    "        main = formatted_conversation + \"\\n\" + f\"Total question count: {question_count}\"\n",
    "\n",
    "        return (base_prompt, main)\n",
    "\n",
    "profile, data = get_prompt(patient_data={'name': 'Avijit bhuin', 'age': 22, 'gender': 'Male', 'height': '', 'weight': '', 'blood_group': 'A+', 'symptoms': 'fever', 'medical_history': '', 'medications': '', 'allergies': ''},\n",
    "conversation=[{'role': 'assistant', 'content': \"I understand your concern about 'hii'. This is a placeholder response. In a real implementation, this would be connected to a medical AI model that can provide appropriate medical guidance while noting that it's not a replacement for professional medical advice.\"}, {'role': 'user', 'content': 'hii'}, {'role': 'assistant', 'content': 'okk'}, {'role': 'user', 'content': 'okk'}])\n",
    "\n",
    "print(profile)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
